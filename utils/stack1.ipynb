{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 47500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=9)\n",
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../../X_train.npz')['arr_0']\n",
    "Y = np.load('../../Y_train.npz')['arr_0']\n",
    "TX = np.load('../../X_test.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX = np.concatenate((X, TX), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX_square = XTX ** 2\n",
    "XTX_cumsum = np.concatenate((np.cumsum(XTX[:, :5000], axis=1), np.cumsum(XTX[:, 5000:], axis=1)), axis=1)\n",
    "XTX_all = np.concatenate((XTX, XTX_square, XTX_cumsum), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test = XTX_all[:train_size], XTX_all[train_size:]\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate type 1 error\n",
    "def err1(y, y_pred):\n",
    "    return np.sum(1.0 * np.abs(y_pred - y)) / len(y_pred)\n",
    "\n",
    "# calculate type 2 errr\n",
    "def err2(y, y_pred):\n",
    "    return np.sum(np.abs(y_pred - y) / y) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = {'t1':make_scorer(err1, greater_is_better=False), 't2':make_scorer(err2, greater_is_better=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best params\n",
    "model = LinearRegression()\n",
    "params = {'fit_intercept':[True, False]}\n",
    "fit_params = {}\n",
    "\n",
    "clf = GridSearchCV(estimator=model, param_grid=params, scoring=scorer['t1'], n_jobs=1, cv=5, verbose=1)\n",
    "clf.fit(X, Y)#, fit_params=fit_params)\n",
    "t1_best_params = clf.best_params_\n",
    "print(t1_best_params)\n",
    "\n",
    "clf = GridSearchCV(estimator=model, param_grid=params, scoring=scorer['t2'], n_jobs=1, cv=5, verbose=1)\n",
    "clf.fit(X, Y)#, fit_params=fit_params)\n",
    "t2_best_params = clf.best_params_\n",
    "print(t2_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = []\n",
    "vy = []\n",
    "\n",
    "for y_id in range(3):\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    tty = []\n",
    "    tvy = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = Y[train_idx, y_id], Y[val_idx, y_id]\n",
    "        \n",
    "        model = LinearRegression(t1_best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        tvy.append(model.predict(X_val))\n",
    "        tty.append(model.predict(X_test))\n",
    "    vy.append(np.concatenate((tvy[0], tvy[1], tvy[2], tvy[3], tvy[4]), axis=0))\n",
    "    ty.append(np.mean(np.array(tty), axis=0))\n",
    "\n",
    "ty = np.array(ty).transpose()\n",
    "vy = np.array(vy).transpose()\n",
    "df = pd.DataFrame(ty)\n",
    "df.to_csv('t1_test.csv', index=False, header=False)\n",
    "df = pd.DataFrame(vy)\n",
    "df.to_csv('t1_val.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = []\n",
    "vy = []\n",
    "\n",
    "for y_id in range(3):\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    tty = []\n",
    "    tvy = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = Y[train_idx, y_id], Y[val_idx, y_id]\n",
    "        \n",
    "        model = LinearRegression(t2_best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        tvy.append(model.predict(X_val))\n",
    "        tty.append(model.predict(X_test))\n",
    "    vy.append(np.concatenate((tvy[0], tvy[1], tvy[2], tvy[3], tvy[4]), axis=0))\n",
    "    ty.append(np.mean(np.array(tty), axis=0))\n",
    "\n",
    "ty = np.array(ty).transpose()\n",
    "vy = np.array(vy).transpose()\n",
    "df = pd.DataFrame(ty)\n",
    "df.to_csv('t2_test.csv', index=False, header=False)\n",
    "df = pd.DataFrame(vy)\n",
    "df.to_csv('t2_val.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
