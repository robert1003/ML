{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 47500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=9)\n",
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../../X_train.npz')['arr_0']\n",
    "Y = np.load('../../Y_train.npz')['arr_0']\n",
    "TX = np.load('../../X_test.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX = np.concatenate((X, TX), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, TX = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX_square = XTX ** 2\n",
    "XTX_cumsum = np.concatenate((np.cumsum(XTX[:, :5000], axis=1), np.cumsum(XTX[:, 5000:], axis=1)), axis=1)\n",
    "XTX_all = np.concatenate((XTX, XTX_square, XTX_cumsum), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX, XTX_square, XTX_cumsum = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test = XTX_all[:train_size], XTX_all[train_size:]\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate type 1 error\n",
    "def err1(y, y_pred):\n",
    "    return np.sum(1.0 * np.abs(y_pred - y)) / len(y_pred)\n",
    "\n",
    "# calculate type 2 errr\n",
    "def err2(y, y_pred):\n",
    "    return np.sum(np.abs(y_pred - y) / y) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = {'t1':make_scorer(err1, greater_is_better=False), 't2':make_scorer(err2, greater_is_better=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best params\n",
    "y_id = 0\n",
    "idx = np.random.permutation(47500)[:1000]\n",
    "X_tmp, y_tmp = X[idx], Y[idx]\n",
    "params = {'boosting_type':['gbdt', 'dart'],\n",
    "          'num_leaves':[31, 511],\n",
    "          'learning_rate':[0.05],\n",
    "          'n_estimators':[100],\n",
    "          'n_jobs':[23]}\n",
    "\n",
    "t1_err = np.Inf\n",
    "t2_err = np.Inf\n",
    "t1_best_params = {}\n",
    "t2_best_params = {}\n",
    "keys, values = zip(*params.items())\n",
    "for v in itertools.product(*values):\n",
    "    param = dict(zip(keys, v))\n",
    "    print(param)\n",
    "    t1_errr = 0\n",
    "    t2_errr = 0\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    for train_idx, val_idx in kf.split(X_tmp):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = Y[train_idx, y_id], Y[val_idx, y_id]\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        t1_errr += err1(model.predict(X_val), y_val)\n",
    "        t2_errr += err2(model.predict(X_val), y_val)\n",
    "    \n",
    "    if t1_errr / 5 < t1_err:\n",
    "        t1_best_params = param\n",
    "        t1_err = t1_errr / 5\n",
    "    if t2_errr / 5 < t2_err:\n",
    "        t2_best_params = param\n",
    "        t2_err = t2_errr / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = []\n",
    "vy = []\n",
    "\n",
    "for y_id in range(3):\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    tty = []\n",
    "    tvy = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = Y[train_idx, y_id], Y[val_idx, y_id]\n",
    "        \n",
    "        model = LinearRegression(t1_best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        tvy.append(model.predict(X_val))\n",
    "        tty.append(model.predict(X_test))\n",
    "\n",
    "        print(err1(model.predict(X_train), y_train), err2(model.predict(X_train), y_train))\n",
    "        print(err1(tvy[-1], y_val), err2(tvy[-1], y_val))\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = None, None, None, None\n",
    "    vy.append(np.concatenate((tvy[0], tvy[1], tvy[2], tvy[3], tvy[4]), axis=0))\n",
    "    ty.append(np.mean(np.array(tty), axis=0))\n",
    "\n",
    "ty = np.array(ty).transpose()\n",
    "vy = np.array(vy).transpose()\n",
    "df = pd.DataFrame(ty)\n",
    "df.to_csv('t1_test.csv', index=False, header=False)\n",
    "df = pd.DataFrame(vy)\n",
    "df.to_csv('t1_val.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = []\n",
    "vy = []\n",
    "\n",
    "for y_id in range(3):\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    tty = []\n",
    "    tvy = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = Y[train_idx, y_id], Y[val_idx, y_id]\n",
    "        \n",
    "        model = LinearRegression(t2_best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        tvy.append(model.predict(X_val))\n",
    "        tty.append(model.predict(X_test))\n",
    "        \n",
    "        print(err1(model.predict(X_train), y_train), err2(model.predict(X_train), y_train))\n",
    "        print(err1(tvy[-1], y_val), err2(tvy[-1], y_val))        \n",
    "        \n",
    "        X_train, X_val, y_train, y_val = None, None, None, None\n",
    "    vy.append(np.concatenate((tvy[0], tvy[1], tvy[2], tvy[3], tvy[4]), axis=0))\n",
    "    ty.append(np.mean(np.array(tty), axis=0))\n",
    "\n",
    "ty = np.array(ty).transpose()\n",
    "vy = np.array(vy).transpose()\n",
    "df = pd.DataFrame(ty)\n",
    "df.to_csv('t2_test.csv', index=False, header=False)\n",
    "df = pd.DataFrame(vy)\n",
    "df.to_csv('t2_val.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
